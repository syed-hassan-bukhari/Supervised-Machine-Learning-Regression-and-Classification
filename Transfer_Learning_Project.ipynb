{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning Project**\n",
        "# “Image Classification Using a Pretrained Model”\n",
        "\n",
        "**Objective**\n",
        "\n",
        "Use a pretrained CNN (trained on ImageNet) and adapt it to a new task with limited data.\n",
        "\n",
        "**You will learn:**\n",
        "\n",
        "- Transfer learning\n",
        "\n",
        "- Feature extraction vs fine-tuning\n",
        "\n",
        "- Freezing & unfreezing layers\n",
        "\n",
        "- Why pretrained models work so well\n",
        "\n",
        "**Why Transfer Learning Is Powerful**\n",
        "\n",
        "- Requires less data\n",
        "\n",
        "- Trains faster\n",
        "\n",
        "- Achieves higher accuracy\n",
        "\n",
        "- Standard practice in industry"
      ],
      "metadata": {
        "id": "GvtqiHGJ_i6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import libraries"
      ],
      "metadata": {
        "id": "ffY5b1ZfAI4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZ02hvGvuB-R"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pretrained Model"
      ],
      "metadata": {
        "id": "pA5Kyjo_AQLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(160, 160, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bnmC51EzurcV",
        "outputId": "795deef6-55d0-4189-948e-42a6a2a32e5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load dataset"
      ],
      "metadata": {
        "id": "jfvZSsScAUVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"shaunthesheep/microsoft-catsvsdogs-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci95O4CSwo5l",
        "outputId": "e7c7a2be-ae99-4b16-abe5-2b57dac6ae0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'microsoft-catsvsdogs-dataset' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "bBlPtrvXAY3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Construct the correct path to the training data\n",
        "train_dir = os.path.join(path, \"PetImages\") # Assuming \"PetImages\" is the folder containing \"Cat\" and \"Dog\"\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(160,160),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(160,160),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eydKkI5vj9z",
        "outputId": "45a26706-9f97-4661-99a2-f104d1680cd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Final Model"
      ],
      "metadata": {
        "id": "AnDkvUehAdVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "QloHuMUBvr-q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Cleaning and Preparation\n",
        "\n",
        "To remove corrupted images by copying the dataset to a writable directory, ensuring error-free data loading and stable model training."
      ],
      "metadata": {
        "id": "z8Tw4KYKAz15"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1264c5d7",
        "outputId": "26ec3637-118e-4159-a59f-d08ed6eaffba"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "# Define the base directory for the images\n",
        "# 'path' variable should be available from previous execution (kagglehub.dataset_download)\n",
        "# train_dir is where the 'Cat' and 'Dog' folders are located\n",
        "image_base_dir = train_dir # This is the original read-only path\n",
        "\n",
        "# Define a writable temporary directory\n",
        "writable_base_dir = '/tmp/PetImages_writable'\n",
        "\n",
        "print(f\"Copying dataset from {image_base_dir} to {writable_base_dir} for cleaning...\")\n",
        "# Ensure the writable base directory exists\n",
        "if os.path.exists(writable_base_dir):\n",
        "    shutil.rmtree(writable_base_dir)\n",
        "shutil.copytree(image_base_dir, writable_base_dir)\n",
        "print(\"Dataset copied successfully.\")\n",
        "\n",
        "def clean_image_directory(directory_path):\n",
        "    print(f\"Cleaning directory: {directory_path}\")\n",
        "    for root, _, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                # Attempt to open the image to check for corruption\n",
        "                img = Image.open(file_path)\n",
        "                img.verify() # Verify if it's a valid image\n",
        "                img.close()\n",
        "            except (IOError, SyntaxError, Image.UnidentifiedImageError, OSError) as e:\n",
        "                print(f\"Deleting corrupted image: {file_path} - Error: {e}\")\n",
        "                os.remove(file_path) # Now this should work as it's in a writable location\n",
        "                # No need for shutil.rmtree for a file, os.remove is sufficient\n",
        "\n",
        "# Clean both 'Cat' and 'Dog' subdirectories in the writable location\n",
        "cat_dir_writable = os.path.join(writable_base_dir, 'Cat')\n",
        "dog_dir_writable = os.path.join(writable_base_dir, 'Dog')\n",
        "\n",
        "clean_image_directory(cat_dir_writable)\n",
        "clean_image_directory(dog_dir_writable)\n",
        "\n",
        "print(\"Dataset cleaning complete on the writable copy.\")\n",
        "\n",
        "# Update train_dir and val_data to point to the cleaned, writable dataset\n",
        "train_dir = writable_base_dir\n",
        "\n",
        "# Re-initialize ImageDataGenerator and flow_from_directory to use the cleaned data\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(160,160),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(160,160),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying dataset from /kaggle/input/microsoft-catsvsdogs-dataset/PetImages to /tmp/PetImages_writable for cleaning...\n",
            "Dataset copied successfully.\n",
            "Cleaning directory: /tmp/PetImages_writable/Cat\n",
            "Deleting corrupted image: /tmp/PetImages_writable/Cat/666.jpg - Error: cannot identify image file '/tmp/PetImages_writable/Cat/666.jpg'\n",
            "Deleting corrupted image: /tmp/PetImages_writable/Cat/Thumbs.db - Error: cannot identify image file '/tmp/PetImages_writable/Cat/Thumbs.db'\n",
            "Cleaning directory: /tmp/PetImages_writable/Dog\n",
            "Deleting corrupted image: /tmp/PetImages_writable/Dog/11702.jpg - Error: cannot identify image file '/tmp/PetImages_writable/Dog/11702.jpg'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting corrupted image: /tmp/PetImages_writable/Dog/Thumbs.db - Error: cannot identify image file '/tmp/PetImages_writable/Dog/Thumbs.db'\n",
            "Dataset cleaning complete on the writable copy.\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Found 4998 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile & Train"
      ],
      "metadata": {
        "id": "ZhvebgaSA-Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_data, epochs=5, validation_data=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81k5ZRY_xCyy",
        "outputId": "4af64a67-c4ad-4bb4-cb49-733738fa6c70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 885ms/step - accuracy: 0.9748 - loss: 0.0742 - val_accuracy: 0.9786 - val_loss: 0.0593\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 877ms/step - accuracy: 0.9786 - loss: 0.0574 - val_accuracy: 0.9756 - val_loss: 0.0594\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 874ms/step - accuracy: 0.9822 - loss: 0.0504 - val_accuracy: 0.9778 - val_loss: 0.0597\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 883ms/step - accuracy: 0.9822 - loss: 0.0467 - val_accuracy: 0.9782 - val_loss: 0.0589\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 880ms/step - accuracy: 0.9863 - loss: 0.0358 - val_accuracy: 0.9778 - val_loss: 0.0604\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2efd8b4ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning"
      ],
      "metadata": {
        "id": "0I6lZ4C6BBS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "MrZX8swC0OCE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_data, epochs=5, validation_data=val_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy5rzfXC--wT",
        "outputId": "691aa167-8d67-406d-efef-5161601de7d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m956s\u001b[0m 1s/step - accuracy: 0.9181 - loss: 0.2031 - val_accuracy: 0.9722 - val_loss: 0.0896\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m897s\u001b[0m 1s/step - accuracy: 0.9679 - loss: 0.0810 - val_accuracy: 0.9720 - val_loss: 0.0844\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m909s\u001b[0m 1s/step - accuracy: 0.9736 - loss: 0.0667 - val_accuracy: 0.9772 - val_loss: 0.0728\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m878s\u001b[0m 1s/step - accuracy: 0.9791 - loss: 0.0523 - val_accuracy: 0.9778 - val_loss: 0.0723\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m878s\u001b[0m 1s/step - accuracy: 0.9830 - loss: 0.0421 - val_accuracy: 0.9746 - val_loss: 0.0768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2efdde7e00>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}